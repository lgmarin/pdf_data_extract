{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF File Data Extractor\n",
    "This Notebook is a helper to extract data from a PDF file. \n",
    "The PDF contains data for planting different types of vegetables. The PDF is available by the Brazilian State Owned Company EMBRAPA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies\n",
    "\n",
    "For general data extraction from a pdf file, I'm using the [PyMuPDF](https://github.com/pymupdf/PyMuPDF-Utilities) package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymupdf in c:\\users\\luiz.marin\\anaconda3\\lib\\site-packages (1.19.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#Install Dependencies - PymuPDF\n",
    "%pip install pymupdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import PyMuPDF package and configurations\n",
    "\n",
    "PyMuPDF is loaded into python via the fitz package.\n",
    "\n",
    "Here I'm also setting the initial and final pages of the PDF that I want to read.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import os\n",
    "\n",
    "# --> Load PDF file\n",
    "# Specify pdf file name (inside pdf folder)\n",
    "pdf_name = \"tabela_embrapa_clean.pdf\"\n",
    "pdf_file = os.path.join(\"pdf\", pdf_name)\n",
    "\n",
    "# --> Set Initial and Final Pages of the Document to search\n",
    "initial_page = 8\n",
    "final_page = 57\n",
    "\n",
    "# Load PDF\n",
    "pdf_document = fitz.open(pdf_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extraction\n",
    "\n",
    "The data could be extract in form o words or blocks. The usage may provided more or less relevant results according to the pdf file being read. For this case, I found that reading the blocks of content from the page provided better results.\n",
    "\n",
    "The get method with the blocks option will return for each page a list with all the elements in the page such as text blocks and images, each of those items are in the form of another list with the position of the block in the document, the data (if it is an image or a image mask) or the text, that is what we are interested!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = []\n",
    "\n",
    "for page in range(initial_page-1, final_page-1):\n",
    "    pdf_page = pdf_document[page]\n",
    "    pages.append(pdf_page.get_text(\"blocks\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "If you take a look at the results of the extraction process above, you will see that our data is not in a very nice way. I'm interested in getting the results in form of a list and a dict so I can choose later which will suit best for my application.\n",
    "\n",
    "On a first step, I will need to find among all of the other blocks from the page, just the ones that I'm interested, being the ones that contains the Name, Scientific Name, Description, Epoch and Crop region and Recommendations. To search for those I'm using the find() method.\n",
    "\n",
    "Together with the finding the relevant data, I'm also cleaning the data and splitting into a name:data pair (thats why I will also generate a dict, that could be used as a JSON latter). To do that I'm using the replace(\"search\", \"replace\", number of times) method that search a string and replace it with the second argument, the third argument is a breakpoint, to tell how many times the method should replace the item, here I just want it to execute one time.\n",
    "\n",
    "To clean things up, I'm also replacing the break lines and then I will split the data, here, as I did with the replace() method, I just want it to run once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean Data\n",
    "#Search for first item\n",
    "clean_page = []\n",
    "clean_dict = []\n",
    "clean_list = []\n",
    "for page in pages:\n",
    "    for item in page:\n",
    "        if item[4].find(\"Nome popular\") != -1:\n",
    "            temp = item[4].replace(\"-\",\"–\", 1).replace('\\n', ' ').split(\"–\", 1)\n",
    "            temp[0] = temp[0].rstrip()\n",
    "            temp[1] = temp[1].lstrip()\n",
    "            clean_list.append(temp)\n",
    "        elif item[4].find(\"Nome científico\") != -1:\n",
    "            temp = item[4].replace(\"-\",\"–\", 1).replace('\\n', ' ').split(\"–\", 1)\n",
    "            temp[0] = temp[0].rstrip()\n",
    "            temp[1] = temp[1].lstrip()\n",
    "            clean_list.append(temp)\n",
    "        elif item[4].find(\"Descrição\") != -1:\n",
    "            temp = item[4].replace(\"-\",\"–\", 1).replace('\\n', ' ').split(\"–\", 1)\n",
    "            temp[0] = temp[0].rstrip()\n",
    "            temp[1] = temp[1].lstrip()\n",
    "            clean_list.append(temp)\n",
    "        elif item[4].find(\"Época e regiões para plantio\") != -1:\n",
    "            temp = item[4].replace(\"-\",\"–\", 1).replace('\\n', ' ').split(\"–\", 1)\n",
    "            temp[0] = temp[0].rstrip()\n",
    "            temp[1] = temp[1].lstrip()\n",
    "            clean_list.append(temp)           \n",
    "        elif item[4].find(\"Recomendações para aproveitamento\") != -1:\n",
    "            temp = item[4].replace(\"-\",\"–\", 1).replace('\\n', ' ').split(\"–\", 1)\n",
    "            temp[0] = temp[0].rstrip()\n",
    "            temp[1] = temp[1].lstrip()\n",
    "            clean_list.append(temp)\n",
    "    clean_page.append(clean_list)\n",
    "    clean_dict.append(dict(clean_list))\n",
    "    clean_list = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally\n",
    "\n",
    "And thats it! We have now a clean and ready data to use in different scenarios. For these data, I'm planning to build a kitchen garden management that will provide useful data about the main crops. The next step will be to extract data from a PDF table. That could be a more challenging subject, as the pdf don't have a structure for the table, is just a bunch of blocks of text and graphical data (that represents the lines). If we try to read the blocks we just get a random text mess that will be hard to visualize.\n",
    "\n",
    "But for our lucky, that are many other tools to help with that!\n",
    "\n",
    "Until next time!"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f1023349960d19f96f872dda9d5b5e94247ae02a66ea97e0746d4b96d9ae62d7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
